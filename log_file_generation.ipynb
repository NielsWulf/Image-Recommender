{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Load PCA-reduced embeddings and image paths\n",
    "pca_embeddings_path = \"combined_embeddings.pkl\"\n",
    "db_path = \"image_metadata.db\"\n",
    "\n",
    "# Load the PCA-reduced embeddings\n",
    "with open(pca_embeddings_path, \"rb\") as f:\n",
    "    embeddings_data = pickle.load(f)\n",
    "\n",
    "uuids = list(embeddings_data.keys())\n",
    "embeddings = np.array(list(embeddings_data.values()))\n",
    "\n",
    "\n",
    "# Function to fetch image paths from SQLite database\n",
    "def fetch_image_paths_from_db(db_path, uuids, batch_size=512):\n",
    "    image_paths = {}\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    for i in tqdm(range(0, len(uuids), batch_size), desc=\"Fetching image paths\"):\n",
    "        uuid_batch = uuids[i : i + batch_size]\n",
    "        placeholders = \", \".join(\"?\" for _ in uuid_batch)\n",
    "        query = f\"SELECT uuid, file_path FROM images WHERE uuid IN ({placeholders})\"\n",
    "        cursor.execute(query, uuid_batch)\n",
    "        rows = cursor.fetchall()\n",
    "        image_paths.update({uuid: file_path for uuid, file_path in rows})\n",
    "\n",
    "    conn.close()\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "# Fetch image paths\n",
    "image_paths = fetch_image_paths_from_db(db_path, uuids)\n",
    "\n",
    "# Reduce the size of images\n",
    "image_size = (32, 32)\n",
    "transform = transforms.Compose([transforms.Resize(image_size), transforms.ToTensor()])\n",
    "\n",
    "# Process images in batches\n",
    "batch_size = 512\n",
    "num_batches = len(embeddings) // batch_size + 1\n",
    "\n",
    "# Global log directory for all experiments\n",
    "global_log_dir = \"logs/pca_embeddings\"\n",
    "\n",
    "# Experiment-specific subdirectory (using a timestamp for uniqueness)\n",
    "experiment_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "experiment_log_dir = os.path.join(global_log_dir, experiment_name)\n",
    "\n",
    "os.makedirs(experiment_log_dir, exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(experiment_log_dir)\n",
    "\n",
    "# Add progress bar with tqdm\n",
    "for i in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(embeddings))\n",
    "\n",
    "    batch_embeddings = embeddings[start_idx:end_idx]\n",
    "    batch_uuids = uuids[start_idx:end_idx]\n",
    "    batch_image_paths = [image_paths[uuid] for uuid in batch_uuids]\n",
    "    batch_labels = [os.path.basename(path) for path in batch_image_paths]\n",
    "\n",
    "    batch_images = []\n",
    "    for path in batch_image_paths:\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img_tensor = transform(img)\n",
    "            batch_images.append(img_tensor)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {path}: {e}\")\n",
    "            batch_images.append(torch.zeros(3, *image_size))\n",
    "\n",
    "    batch_images = torch.stack(batch_images)\n",
    "\n",
    "    # Debugging: Check tensor sizes before logging\n",
    "    print(\n",
    "        f\"Logging batch {i+1}/{num_batches} with {len(batch_embeddings)} embeddings and {len(batch_images)} images.\"\n",
    "    )\n",
    "    print(f\"  - Embeddings shape: {batch_embeddings.shape}\")\n",
    "    print(f\"  - Images tensor shape: {batch_images.shape}\")\n",
    "\n",
    "    writer.add_embedding(\n",
    "        torch.tensor(batch_embeddings),\n",
    "        metadata=batch_labels,\n",
    "        label_img=batch_images,\n",
    "        global_step=i,  # Different step for each batch\n",
    "    )\n",
    "\n",
    "# Flush and close the writer\n",
    "writer.flush()\n",
    "writer.close()\n",
    "print(f\"Embeddings logged to {experiment_log_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define the root directory containing all subfolders\n",
    "root_dir = \"logs\\\\pca_embeddings\\\\20240812-130708\"\n",
    "folders = [\n",
    "    f for f in sorted(os.listdir(root_dir)) if os.path.isdir(os.path.join(root_dir, f))\n",
    "]\n",
    "\n",
    "# Initialize lists to hold combined data\n",
    "all_embeddings = []\n",
    "all_metadata = []\n",
    "all_label_imgs = []\n",
    "\n",
    "sprite_size = (32, 32)  # Reduced sprite size to make the overall log size smaller\n",
    "max_sprite_dim = 4096  # TensorBoard max allowed dimensions\n",
    "\n",
    "# Initial batch size\n",
    "batch_size = 100  # Start with a small batch size\n",
    "max_batch_size = 100  # Max batch size to prevent excessive memory usage\n",
    "batch_counter = 0\n",
    "\n",
    "\n",
    "# Function to filter out black or nearly black images\n",
    "def is_black_or_nearly_black(img_tensor, threshold=10):\n",
    "    return img_tensor.mean() < threshold / 255.0\n",
    "\n",
    "\n",
    "# Function to split large sprites into smaller ones\n",
    "def split_sprite(sprite_img, sprite_size, max_sprite_dim):\n",
    "    sprite_width, sprite_height = sprite_img.size\n",
    "    n_images_x = sprite_width // sprite_size[0]\n",
    "    n_images_y = sprite_height // sprite_size[1]\n",
    "\n",
    "    sub_sprites = []\n",
    "    sub_labels = []\n",
    "    x_splits = max_sprite_dim // sprite_size[0]\n",
    "    y_splits = max_sprite_dim // sprite_size[1]\n",
    "\n",
    "    for i in range(0, n_images_y, y_splits):\n",
    "        for j in range(0, n_images_x, x_splits):\n",
    "            box = (\n",
    "                j * sprite_size[0],\n",
    "                i * sprite_size[1],\n",
    "                min((j + x_splits) * sprite_size[0], sprite_width),\n",
    "                min((i + y_splits) * sprite_size[1], sprite_height),\n",
    "            )\n",
    "            sub_sprite = sprite_img.crop(box)\n",
    "            sub_sprites.append(sub_sprite)\n",
    "\n",
    "            # Calculate the number of images in this sub-sprite\n",
    "            sub_nx = (box[2] - box[0]) // sprite_size[0]\n",
    "            sub_ny = (box[3] - box[1]) // sprite_size[1]\n",
    "\n",
    "            # Create labels for this sub-sprite\n",
    "            sub_labels.extend(\n",
    "                [\n",
    "                    f\"sprite_{len(sub_sprites) - 1}_{x}_{y}\"\n",
    "                    for y in range(sub_ny)\n",
    "                    for x in range(sub_nx)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return sub_sprites, sub_labels\n",
    "\n",
    "\n",
    "# Function to save batch data\n",
    "def save_batch(batch_counter, all_embeddings, all_metadata, all_label_imgs):\n",
    "    # Concatenate all data\n",
    "    embeddings_combined = torch.cat(all_embeddings, dim=0)\n",
    "    label_img_combined = torch.cat(all_label_imgs, dim=0)\n",
    "\n",
    "    # Ensure all arrays have the same number of elements\n",
    "    min_length = min(\n",
    "        len(embeddings_combined), len(all_metadata), len(label_img_combined)\n",
    "    )\n",
    "    embeddings_combined = embeddings_combined[:min_length]\n",
    "    all_metadata = all_metadata[:min_length]\n",
    "    label_img_combined = label_img_combined[:min_length]\n",
    "\n",
    "    # Create TensorBoard writer\n",
    "    log_dir = f\"logs/combined_embeddings_try2/{batch_counter:05d}\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    # Log embeddings under a common name\n",
    "    writer.add_embedding(\n",
    "        embeddings_combined,\n",
    "        metadata=all_metadata,\n",
    "        label_img=label_img_combined,\n",
    "        tag=\"Combined Embeddings\",\n",
    "        global_step=0,\n",
    "    )\n",
    "\n",
    "    # Flush and close the writer\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    print(f\"Combined embeddings logged to {log_dir}.\")\n",
    "\n",
    "\n",
    "# Iterate over each folder and load data\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(\n",
    "        root_dir, folder, \"default\"\n",
    "    )  # Include 'default' in the path\n",
    "\n",
    "    # Load metadata\n",
    "    metadata_file = os.path.join(folder_path, \"metadata.tsv\")\n",
    "    metadata = pd.read_csv(metadata_file, sep=\"\\t\", header=None)\n",
    "    all_metadata.extend(metadata.values.flatten().tolist())\n",
    "\n",
    "    # Load tensors\n",
    "    tensors_file = os.path.join(folder_path, \"tensors.tsv\")\n",
    "    tensors = pd.read_csv(tensors_file, sep=\"\\t\", header=None)\n",
    "    tensor_embeddings = torch.tensor(tensors.values, dtype=torch.float32)\n",
    "    all_embeddings.append(tensor_embeddings)\n",
    "\n",
    "    # Calculate cosine similarity and cluster similar embeddings\n",
    "    similarities = cosine_similarity(tensor_embeddings)\n",
    "    sorted_indices = np.argsort(similarities, axis=1)[\n",
    "        :, ::-1\n",
    "    ]  # Sort by descending similarity\n",
    "\n",
    "    # Load and split sprite image\n",
    "    sprite_file = os.path.join(folder_path, \"sprite.png\")\n",
    "    sprite_img = Image.open(sprite_file)\n",
    "    sub_sprites, sub_labels = split_sprite(sprite_img, sprite_size, max_sprite_dim)\n",
    "\n",
    "    # Process each sub-sprite, keeping only similar images and filtering out black images\n",
    "    for sub_sprite in sub_sprites:\n",
    "        sprite_width, sprite_height = sub_sprite.size\n",
    "        n_images_x = sprite_width // sprite_size[0]\n",
    "        n_images_y = sprite_height // sprite_size[1]\n",
    "\n",
    "        label_imgs = []\n",
    "        for i in range(n_images_y):\n",
    "            for j in range(n_images_x):\n",
    "                box = (\n",
    "                    j * sprite_size[0],\n",
    "                    i * sprite_size[1],\n",
    "                    (j + 1) * sprite_size[0],\n",
    "                    (i + 1) * sprite_size[1],\n",
    "                )\n",
    "                img = sub_sprite.crop(box)\n",
    "                img_tensor = transforms.ToTensor()(img)\n",
    "\n",
    "                # Filter out black or nearly black images\n",
    "                if not is_black_or_nearly_black(img_tensor):\n",
    "                    label_imgs.append(img_tensor)\n",
    "\n",
    "        if label_imgs:\n",
    "            all_label_imgs.append(torch.stack(label_imgs))\n",
    "\n",
    "    # Check if the combined sprite, metadata, or embeddings are exceeding memory or dimension limits\n",
    "    if (\n",
    "        len(all_embeddings) >= batch_size\n",
    "        or sum([img.nelement() for img in all_label_imgs]) >= max_sprite_dim**2\n",
    "        or len(all_metadata) >= max_sprite_dim**2\n",
    "    ):\n",
    "        save_batch(batch_counter, all_embeddings, all_metadata, all_label_imgs)\n",
    "        batch_counter += 1\n",
    "\n",
    "        # Adjust batch size dynamically based on the previous batch\n",
    "        if len(all_embeddings) >= batch_size:\n",
    "            batch_size = min(\n",
    "                batch_size + 10, max_batch_size\n",
    "            )  # Increase batch size if possible\n",
    "        else:\n",
    "            batch_size = max(batch_size - 10, 10)  # Decrease batch size if necessary\n",
    "\n",
    "        # Reset lists for the next batch\n",
    "        all_embeddings = []\n",
    "        all_metadata = []\n",
    "        all_label_imgs = []\n",
    "\n",
    "# Save any remaining data after the loop ends\n",
    "if all_embeddings:\n",
    "    save_batch(batch_counter, all_embeddings, all_metadata, all_label_imgs)\n",
    "\n",
    "print(f\"Processed {batch_counter + 1} batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
